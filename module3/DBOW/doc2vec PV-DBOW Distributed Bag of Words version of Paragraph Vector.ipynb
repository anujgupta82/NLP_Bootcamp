{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "doc2vec PV-DBOW Distributed Bag of Words version of Paragraph Vector.ipynb",
      "version": "0.3.2",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtPCc3S4wvBn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # Nachiss - import nltk\n",
        " # nltk.download('punkt')\n",
        "# NACHISS - !pip install ggplot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9xb2l9BwriQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%reload_ext autoreload\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9Q64J-_0SNx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "bda8f259-f9a0-4e09-e33f-d9541a91b005"
      },
      "source": [
        "!pip install ggplot"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ggplot\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/04/5c88cc51c6713583f2dc78a5296adb9741505348c323d5875bc976143db2/ggplot-0.11.5-py2.py3-none-any.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2MB 4.9MB/s \n",
            "\u001b[?25hCollecting brewer2mpl (from ggplot)\n",
            "  Downloading https://files.pythonhosted.org/packages/84/57/00c45a199719e617db0875181134fcb3aeef701deae346547ac722eaaf5e/brewer2mpl-1.4.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.6/dist-packages (from ggplot) (0.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from ggplot) (1.16.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from ggplot) (1.12.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from ggplot) (0.24.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from ggplot) (3.0.3)\n",
            "Requirement already satisfied: patsy>=0.4 in /usr/local/lib/python3.6/dist-packages (from ggplot) (0.5.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from ggplot) (1.3.1)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.6/dist-packages (from ggplot) (0.10.1)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas->ggplot) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->ggplot) (2018.9)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->ggplot) (2.4.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->ggplot) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->ggplot) (41.2.0)\n",
            "Installing collected packages: brewer2mpl, ggplot\n",
            "Successfully installed brewer2mpl-1.4.1 ggplot-0.11.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApEKnGYDwriT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/GoogleDrive_Utils/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPaetXJUwriX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf \n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import nltk\n",
        "import math\n",
        "import random\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.utils import shuffle\n",
        "from load_imdb_data import load_imdb_data\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "np.random.seed(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mPrOiIpwriZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = open(\"/content/drive/NLP_bootcamp/Data/intent_data.txt\").readlines()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gO0SJwaKwrid",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data[1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9A1nqUJwrig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence = []\n",
        "labels = []\n",
        "\n",
        "for item in data:\n",
        "    temp = item.split('   ')\n",
        "    sentence.append(temp[0].strip())\n",
        "    labels.append(temp[1].strip().replace(\"\\n\", ''))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cVcg3kdwrii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#sentence = [line.decode('utf-8').strip() for line in sentence]\n",
        "sentence = [line.strip() for line in sentence]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjiZI7rowrim",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame()\n",
        "df['review'] = sentence\n",
        "df['label'] = labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcX2baBAwrio",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df[df['label'].isin(['food', 'travel', 'career'])]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDOmhVhiwris",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSFH1HvNwriw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "52f6d51c-a15f-45ff-9058-4612defc9bd2"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I really want a hot dog . My co-workers went t...</td>\n",
              "      <td>food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I wanna go to the beach , but ... Where is the...</td>\n",
              "      <td>travel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I really look forward to Egypt next week ! Its...</td>\n",
              "      <td>travel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I should buy more oatmeal cookies .. I just at...</td>\n",
              "      <td>food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I want pancakes , should I make some ???</td>\n",
              "      <td>food</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review   label\n",
              "0  I really want a hot dog . My co-workers went t...    food\n",
              "1  I wanna go to the beach , but ... Where is the...  travel\n",
              "2  I really look forward to Egypt next week ! Its...  travel\n",
              "3  I should buy more oatmeal cookies .. I just at...    food\n",
              "4           I want pancakes , should I make some ???    food"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mwYqRqXwri1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def processDocs(documents, vocab_size=5000):\n",
        "    \"\"\"\n",
        "    This functions takes in a collection of documents and generates a vocabulary based on the size given in input. \n",
        "    It returns a representation for each document in the list of input documents. \n",
        "    \"\"\"\n",
        "    vocab = {} \n",
        "    doc_id = 0 \n",
        "    doc_ids = []\n",
        "    \n",
        "    for doc in documents:\n",
        "        doc_ids.append(doc_id)                          # Give an ID to each document \n",
        "        doc_id += 1\n",
        "        \n",
        "        for word in nltk.word_tokenize(doc):            # Generate a vocabulary while iterating threw the documents \n",
        "            if word not in vocab:\n",
        "                vocab[word] = 1 \n",
        "            else:\n",
        "                vocab[word] += 1\n",
        "    \n",
        "    # Extract the most frequent words based on the vocabulary size \n",
        "    freq_words_list = sorted(vocab.items(), key=lambda x: x[1], reverse=True)[:vocab_size]\n",
        "    freq_words_set = set([item[0] for item in freq_words_list])\n",
        "    \n",
        "    # Give an index to each word in vocabulary \n",
        "    word2idx = {}         \n",
        "    index_word = 0\n",
        "    for word in freq_words_set:\n",
        "        word2idx[word] = index_word\n",
        "        index_word += 1\n",
        "    word2idx['UNK'] = index_word\n",
        "    \n",
        "    doc_repr = []                          # Represent each document with representation based on the vocabulary  \n",
        "    for doc in documents:\n",
        "        temp = []\n",
        "        for w in doc:\n",
        "            if w in word2idx:\n",
        "                temp.append(word2idx[w])\n",
        "            else:\n",
        "                temp.append(word2idx['UNK'])\n",
        "        doc_repr.append(temp)\n",
        "        \n",
        "    return documents, doc_ids, word2idx, doc_repr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "FDTghqHFwri3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "docs, doc_ids, word2ids, doc_repr = processDocs(df['review'], vocab_size=5000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mqhDB-Zwri9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4ac70744-9ace-4846-8b97-5e864c1b220b"
      },
      "source": [
        "print(len(docs), len(doc_ids), len(word2ids), len(doc_repr))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "591 591 1900 591\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZeWQSwgwrjA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gSbZnnAwrjC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxcpoOXUwrjF",
        "colab_type": "text"
      },
      "source": [
        "## Architecture - PV-DBOW Distributed Bag of Words version of Paragraph Vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LZFvZiXwrjG",
        "colab_type": "text"
      },
      "source": [
        "### Adding batchsizes for speedup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "em5Orv--wrjH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bucket_list = []\n",
        "\n",
        "def generate_batch_pvdbow(doc_ids, doc_repr, sample_size=20, batch_size=1000, window_size=7):\n",
        "    global bucket_list\n",
        "\n",
        "    docs_ids_to_select = list(set(doc_ids) - set(bucket_list))\n",
        "    \n",
        "    \n",
        "    if len(docs_ids_to_select) < batch_size//sample_size:\n",
        "        bucket_list = []\n",
        "        docs_ids_to_select = doc_ids\n",
        "        \n",
        "    index = 0 \n",
        "    train_dX = np.ndarray(shape=(batch_size, 1), dtype=np.int32)\n",
        "    train_label = np.ndarray(shape=(batch_size, window_size), dtype=np.int32)\n",
        "    random_docs = random.sample(docs_ids_to_select, batch_size//sample_size)    # Choose set of random documents \n",
        "\n",
        "    bucket_list += random_docs\n",
        "    \n",
        "    for id_ in random_docs:\n",
        "        for j in range(sample_size):                                 # Generating a dataset of sample size \n",
        "            random_index = random.randint(0, len(doc_repr[id_]) - window_size)\n",
        "            sample_window = doc_repr[id_][random_index: random_index + window_size]\n",
        "            train_dX[index] = id_\n",
        "            train_label[index] = sample_window\n",
        "            index += 1\n",
        "    return train_dX, train_label "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78xaZHpswrjK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc_size = len(docs)\n",
        "embedding_size_d = 100\n",
        "embedding_size_w = 100\n",
        "vocab_size = len(word2ids)\n",
        "window_size = 7\n",
        "n_neg_samples = 20\n",
        "learning_rate = 10e-2\n",
        "epochs = 10001\n",
        "batch_size=1000\n",
        "mu=0.99"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZLygX-WwrjN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define placeholders for training \n",
        "train_dX = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
        "train_label = tf.placeholder(tf.int32, shape=[batch_size, window_size])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTyDozjIwrjP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc_embedding_np = np.random.randn(doc_size, embedding_size_d)/np.sqrt(doc_size + embedding_size_d)\n",
        "word_embedding_np = np.random.randn(vocab_size, embedding_size_w)/np.sqrt(vocab_size + embedding_size_w)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZAywp7KwrjV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define matrix for doc_embedding and word_embedding \n",
        "doc_embedding = tf.Variable(doc_embedding_np.astype(np.float32), name=\"doc_embedding\")\n",
        "word_embedding = tf.Variable(word_embedding_np.astype(np.float32),name=\"word_embedding\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJGwm-NDwrjc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define weights for the output unit \n",
        "weights = tf.Variable(tf.truncated_normal([vocab_size, embedding_size_d], \n",
        "                                       stddev=1.0 / math.sqrt(vocab_size)))\n",
        "biases = tf.Variable(tf.zeros(vocab_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPEmMU5-wrjg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "300b8754-7c0f-4d3b-cb01-d54b4c5c10ac"
      },
      "source": [
        "print (weights.get_shape())"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1900, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W79vJ3elwrji",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add the doc2vec from the doc_embedding \n",
        "embed = tf.nn.embedding_lookup(doc_embedding, train_dX[:, 0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWG5Sng1wrjl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = tf.nn.sampled_softmax_loss(weights=weights, \\\n",
        "                                  biases=biases, \\\n",
        "                                  labels=train_label, \\\n",
        "                                  inputs=embed, \\\n",
        "                                  num_sampled=n_neg_samples, \\\n",
        "                                  num_classes=vocab_size, \\\n",
        "                                  num_true=window_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZcQM9bMwrjp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = tf.reduce_mean(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuxGkBqtwrjr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "e0403b94-7e2c-4edb-cd06-2234c18eb301"
      },
      "source": [
        "optimizer = tf.train.AdagradOptimizer(learning_rate).minimize(loss)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2FQkGXhwrju",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "65700a64-391d-458f-bbf9-845d35fa41ad"
      },
      "source": [
        "import os\n",
        "os.system(\"mkdir /dev/shm/tensorflow_models\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "x_HTD8LRwrjw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "ae4dfc90-3866-447b-ba20-974c29f89d37"
      },
      "source": [
        "saver = tf.train.Saver()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    init = tf.global_variables_initializer()\n",
        "    sess.run(init)\n",
        "    average_loss = 0\n",
        "    \n",
        "    for step in range(epochs):\n",
        "        epoch_error = 0.0\n",
        "        temp_dX, temp_labels = generate_batch_pvdbow(doc_ids=doc_ids, doc_repr=doc_repr)\n",
        "        feed_dict = {train_dX : temp_dX,train_label : temp_labels}\n",
        "        op, l = sess.run([optimizer, loss], \n",
        "                                    feed_dict=feed_dict)\n",
        "        \n",
        "        epoch_error += l\n",
        "                \n",
        "        if step % 1000 == 0:\n",
        "            print (\"Error at epoch : \", step, \" = \", epoch_error)\n",
        "            \n",
        "    save_path = saver.save(sess, \"/dev/shm/tensorflow_models/model_pvdbow_batch_training.ckpt\")\n",
        "    print(\"Model saved in file: %s\" % save_path)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error at epoch :  0  =  2.3425133228302\n",
            "Error at epoch :  1000  =  2.129589319229126\n",
            "Error at epoch :  2000  =  2.0489728450775146\n",
            "Error at epoch :  3000  =  2.001603603363037\n",
            "Error at epoch :  4000  =  2.0373451709747314\n",
            "Error at epoch :  5000  =  1.994558334350586\n",
            "Error at epoch :  6000  =  2.000450372695923\n",
            "Error at epoch :  7000  =  1.9892692565917969\n",
            "Error at epoch :  8000  =  1.9849214553833008\n",
            "Error at epoch :  9000  =  1.9900412559509277\n",
            "Error at epoch :  10000  =  1.983791708946228\n",
            "Model saved in file: /dev/shm/tensorflow_models/model_pvdbow_batch_training.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1gKQiSiwrjz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Qw9sAl9wrj3",
        "colab_type": "text"
      },
      "source": [
        "### Evaluation of the representation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TR27TX7iwrj4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "368bf351-e580-4088-9c27-09133bf9acc8"
      },
      "source": [
        "doc_pvdbow = None\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    saver = tf.train.Saver()\n",
        "    saver.restore(sess, \"/dev/shm/tensorflow_models/model_pvdbow_batch_training.ckpt\")\n",
        "    print(\"Model restored.\")\n",
        "    doc2vec = doc_pvdbow = doc_embedding.eval()\n",
        "    #performanceTest(doc2vec, list(imdb_data['sentiment']), method=None)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from /dev/shm/tensorflow_models/model_pvdbow_batch_training.ckpt\n",
            "Model restored.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUTECvowwrj8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.manifold import TSNE\n",
        "model = TSNE(perplexity=50, n_iter=5000)\n",
        "Z = model.fit_transform(doc_pvdbow) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nojU2BiDwrkA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['axis1'] = Z[:, 0]\n",
        "df['axis2'] = Z[:, 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3FbMjEXwrkE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wD2rIQw-wrkH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "00ed31c1-e83e-4daa-bd15-b41a96de047e"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "      <th>axis1</th>\n",
              "      <th>axis2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I really want a hot dog . My co-workers went t...</td>\n",
              "      <td>food</td>\n",
              "      <td>0.147843</td>\n",
              "      <td>0.733402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I wanna go to the beach , but ... Where is the...</td>\n",
              "      <td>travel</td>\n",
              "      <td>-1.079247</td>\n",
              "      <td>2.179531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I really look forward to Egypt next week ! Its...</td>\n",
              "      <td>travel</td>\n",
              "      <td>-1.518545</td>\n",
              "      <td>2.299939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I should buy more oatmeal cookies .. I just at...</td>\n",
              "      <td>food</td>\n",
              "      <td>1.914252</td>\n",
              "      <td>0.028919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I want pancakes , should I make some ???</td>\n",
              "      <td>food</td>\n",
              "      <td>-2.106158</td>\n",
              "      <td>-0.596058</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  ...     axis2\n",
              "0  I really want a hot dog . My co-workers went t...  ...  0.733402\n",
              "1  I wanna go to the beach , but ... Where is the...  ...  2.179531\n",
              "2  I really look forward to Egypt next week ! Its...  ...  2.299939\n",
              "3  I should buy more oatmeal cookies .. I just at...  ...  0.028919\n",
              "4           I want pancakes , should I make some ???  ... -0.596058\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGcXhHFCwrkJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "b9e26742-51e3-4c69-8d14-89d49c65fdd2"
      },
      "source": [
        "from ggplot import *\n",
        "myplot = ggplot(aes(x='axis1', y='axis2', color='label'), data=df)  + geom_point()\n",
        "myplot.save('myplot.png')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-6129f8ca165f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mggplot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmyplot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mggplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'axis1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'axis2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;34m+\u001b[0m \u001b[0mgeom_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'myplot.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ggplot'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNcmbYDwwrkL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}