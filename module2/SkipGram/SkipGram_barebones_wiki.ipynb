{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "SkipGram_barebones_wiki.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anujgupta82/NLP_Bootcamp/blob/V_2_0/module2/SkipGram/SkipGram_barebones_wiki.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOU3zxKxZbXu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "975c69fb-8901-4c3b-d842-08d02c7b445f"
      },
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 131183 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.11-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.11-0ubuntu1~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.11-0ubuntu1~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06ZLkBwJZX6n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJGMUjF5UEfi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "036a787a-9324-4b1e-f587-657f32098791"
      },
      "source": [
        "!pip install mpld3==0.3\n",
        "!pip install --user \"git+https://github.com/javadba/mpld3@display_fix\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mpld3==0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/95/a52d3a83d0a29ba0d6898f6727e9858fe7a43f6c2ce81a5fe7e05f0f4912/mpld3-0.3.tar.gz (788kB)\n",
            "\u001b[K     |████████████████████████████████| 798kB 2.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: mpld3\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-cp36-none-any.whl size=116679 sha256=9f6f7f263967f8c8551f8f5bbd8c35df86c178d79b9aac7cbd139c4b58835a66\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/47/fb/8a64f89aecfe0059830479308ad42d62e898a3e3cefdf6ba28\n",
            "Successfully built mpld3\n",
            "Installing collected packages: mpld3\n",
            "Successfully installed mpld3-0.3\n",
            "Collecting git+https://github.com/javadba/mpld3@display_fix\n",
            "  Cloning https://github.com/javadba/mpld3 (to revision display_fix) to /tmp/pip-req-build-621xkdpv\n",
            "  Running command git clone -q https://github.com/javadba/mpld3 /tmp/pip-req-build-621xkdpv\n",
            "  Running command git checkout -b display_fix --track origin/display_fix\n",
            "  Switched to a new branch 'display_fix'\n",
            "  Branch 'display_fix' set up to track remote branch 'display_fix' from 'origin'.\n",
            "  Running command git submodule update --init --recursive -q\n",
            "Building wheels for collected packages: mpld3\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3.1.dev1-cp36-none-any.whl size=116957 sha256=998fd1ef0d0a423f97fd5261f1d5430bd512eccf5851f53a435ecf171a563ed1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-99rqh1vd/wheels/68/68/6f/80a05346b88378d8e262669b1ae89773bafe4df4e536e92166\n",
            "Successfully built mpld3\n",
            "Installing collected packages: mpld3\n",
            "Successfully installed mpld3-0.3.1.dev1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Hhf4JIfZX6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import mpld3\n",
        "mpld3.enable_notebook()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xRQ9I4eZX6w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pylab import rcParams\n",
        "rcParams['figure.figsize'] = 10, 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlAziWxFZX6z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import numpy as np \n",
        "import random\n",
        "import math\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "sys.path.append(\"/content/drive/GoogleDrive_Utils/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vB_6D8yaZX62",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from readWikiData import get_wikipedia_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d8fuItgZX66",
        "colab_type": "text"
      },
      "source": [
        "#### Get data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXNwWBDvZX68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences, word2idx, idx2word, _ = get_wikipedia_data(n_files=10, n_vocab=1000, by_paragraph=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJ8LQ4FwZX7A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_wiki_data_skip_gram(sentences, word2idx, window_size=5):\n",
        "    training_data = []\n",
        "    vocab_size = len(word2idx)\n",
        "    for sentence in sentences:\n",
        "        if len(sentence) < window_size * 2 + 1:\n",
        "            continue\n",
        "        for i in range(len(sentence)):\n",
        "            left_context = sentence[max(i-window_size, 0): i]\n",
        "            right_context = sentence[i+1:window_size + i + 1]\n",
        "            centre = sentence[i]\n",
        "            \n",
        "            if len(left_context + right_context) < (2*window_size):\n",
        "                len_left = len(left_context)\n",
        "                len_right = len(right_context)\n",
        "                \n",
        "                if len_left < len_right:\n",
        "                    right_context = sentence[i+1 : window_size + i + 1 + (len_right - len_left)]\n",
        "                else:\n",
        "                    left_context = sentence[max(i-window_size - (len_left - len_right), 0): i]\n",
        "            \n",
        "            temp = left_context + right_context\n",
        "            \n",
        "            if len(temp) < window_size * 2:\n",
        "                print (sentence)\n",
        "                print (left_context)\n",
        "                print (right_context)\n",
        "                print (centre)\n",
        "                break \n",
        "            \n",
        "            training_data.append((centre, tuple(temp)))\n",
        "            \n",
        "            \n",
        "    print (training_data[:10])\n",
        "    training_data = list(set(training_data))\n",
        "    idx2word = {v:k for k, v in word2idx.items()}\n",
        "    return len(word2idx), training_data, word2idx, idx2word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTJqhlDDZX7D",
        "colab_type": "code",
        "outputId": "8d663baf-12dd-4d5c-b6a5-c1a7a6c76dc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "vocab_size, training_data, word2idx, idx2word = get_wiki_data_skip_gram(sentences, word2idx)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(1000, (8, 7, 227, 949, 12, 1000, 1000, 1000, 161, 15)), (8, (1000, 7, 227, 949, 12, 1000, 1000, 1000, 161, 15)), (7, (1000, 8, 227, 949, 12, 1000, 1000, 1000, 161, 15)), (227, (1000, 8, 7, 949, 12, 1000, 1000, 1000, 161, 15)), (949, (1000, 8, 7, 227, 12, 1000, 1000, 1000, 161, 15)), (12, (1000, 8, 7, 227, 949, 1000, 1000, 1000, 161, 15)), (1000, (8, 7, 227, 949, 12, 1000, 1000, 161, 15, 1000)), (1000, (7, 227, 949, 12, 1000, 1000, 161, 15, 1000, 1000)), (1000, (227, 949, 12, 1000, 1000, 161, 15, 1000, 1000, 55)), (161, (949, 12, 1000, 1000, 1000, 15, 1000, 1000, 55, 16))]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_binxTsxZX7H",
        "colab_type": "code",
        "outputId": "ca2298ed-80e6-4c75-e92b-9d438be0f955",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(training_data)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11880092"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgwTWdEaZX7N",
        "colab_type": "code",
        "outputId": "c758fde3-7f93-4928-ab94-d21cb49c0f5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "training_data[:10]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(6, (1000, 1000, 7, 8, 1000, 2, 1000, 1000, 3, 48)),\n",
              " (98, (1000, 2, 170, 50, 1000, 12, 1000, 63, 28, 1000)),\n",
              " (2, (2, 1000, 1000, 1000, 3, 1000, 1000, 5, 153, 201)),\n",
              " (14, (431, 1000, 13, 1000, 1000, 1000, 1000, 55, 653, 27)),\n",
              " (313, (2, 1000, 1000, 2, 1000, 383, 19, 52, 2, 1000)),\n",
              " (1000, (1000, 1000, 1000, 1000, 1000, 205, 20, 246, 6, 21)),\n",
              " (1000, (1000, 1000, 458, 1000, 9, 3, 2, 1000, 1000, 1000)),\n",
              " (1000, (1000, 54, 16, 59, 2, 1000, 3, 282, 14, 1000)),\n",
              " (4, (6, 1000, 708, 1000, 36, 7, 526, 180, 1000, 12)),\n",
              " (310, (382, 1000, 2, 1000, 3, 7, 155, 8, 429, 11))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpdPVi5OZX7Q",
        "colab_type": "text"
      },
      "source": [
        "##### Get batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOWvD7mAZX7R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bucket_list = []\n",
        "\n",
        "def getNextBatchSkipGram(bi_grams_, window_size=5, batch_size=10000):\n",
        "    global bucket_list\n",
        "    docs_ids_to_select = list(set(bi_grams_) - set(bucket_list))\n",
        "    \n",
        "    if len(docs_ids_to_select) < batch_size:\n",
        "        bucket_list = []\n",
        "        docs_ids_to_select = bi_grams_\n",
        "        \n",
        "    # Initialize two variables \n",
        "    train_X = np.ndarray(shape=(batch_size, 1), dtype=np.int32)\n",
        "    train_label = np.ndarray(shape=(batch_size, window_size*2), dtype=np.int32)\n",
        "    \n",
        "    # Get a random set of docs \n",
        "    random_docs = random.sample(docs_ids_to_select, batch_size)\n",
        "    bucket_list += random_docs\n",
        "    \n",
        "    \n",
        "    index = 0 \n",
        "    \n",
        "    # Iterate threw all the docs \n",
        "    for item in random_docs:\n",
        "        train_X[index] = item[0]\n",
        "        train_label[index] = item[1]  \n",
        "        index += 1\n",
        "            \n",
        "    return train_X, train_label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAxpMfRMZX7V",
        "colab_type": "code",
        "outputId": "96a33f60-94b1-4103-9d40-0acdf06218c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "getNextBatchSkipGram(training_data)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[   2],\n",
              "        [1000],\n",
              "        [1000],\n",
              "        ...,\n",
              "        [1000],\n",
              "        [   2],\n",
              "        [1000]], dtype=int32),\n",
              " array([[1000,   64,    2, ...,    5, 1000,   14],\n",
              "        [1000, 1000, 1000, ..., 1000,   10, 1000],\n",
              "        [   7,  764,    6, ..., 1000, 1000, 1000],\n",
              "        ...,\n",
              "        [1000,   10, 1000, ..., 1000, 1000, 1000],\n",
              "        [ 444,   84,    2, ...,    2,   48,  354],\n",
              "        [  16,   45,   13, ..., 1000, 1000,   16]], dtype=int32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPZZmsbwZX7a",
        "colab_type": "text"
      },
      "source": [
        "##### Let's design the graph for skip gram model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c14G0Ng7ZX7b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_weight(Mi, Mo):\n",
        "    shape_sum = float(Mi + Mo) \n",
        "    return np.random.uniform(-np.sqrt(6/shape_sum),np.sqrt(6/shape_sum), [Mi, Mo])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3RO1bsVZX7f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_size_w = 100\n",
        "vocab_size = len(word2idx)\n",
        "n_neg_samples = 20\n",
        "learning_rate = 10e-5\n",
        "epochs = 1001\n",
        "batch_size=10000\n",
        "mu = 0.99\n",
        "window_size = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-qU5OfCZX7j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define placeholders for training \n",
        "train_X = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
        "train_label = tf.placeholder(tf.int32, shape=[batch_size, None])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jm4U2v7TZX7n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define matrix for doc_embedding and word_embedding \n",
        "W1 = tf.Variable(init_weight(vocab_size, embedding_size_w), name=\"W1\", dtype=tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTQq2dbBZX7q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define weights for the output unit \n",
        "W2 = tf.Variable(init_weight(vocab_size, embedding_size_w), name=\"W2\", dtype=tf.float32)\n",
        "biases = tf.Variable(tf.zeros(vocab_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c090P5qeZX7t",
        "colab_type": "code",
        "outputId": "c11d857b-4f63-4892-b1dc-e796c53485d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(train_X.get_shape(), train_label.get_shape(), W1.get_shape(), W2.get_shape())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 1) (10000, ?) (1001, 100) (1001, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1C_wM8aZX7w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embed = tf.nn.embedding_lookup(W1, train_X[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjlS4n4FZX71",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = tf.nn.sampled_softmax_loss(weights=W2, \\\n",
        "                                  biases=biases, \\\n",
        "                                  labels=train_label, \\\n",
        "                                  inputs=embed, \\\n",
        "                                  num_sampled=n_neg_samples, \\\n",
        "                                  num_classes=vocab_size, \n",
        "                                  num_true=window_size*2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXkPG-8BZX77",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = tf.reduce_mean(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7xD3VcuZX8C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=mu).minimize(loss)\n",
        "#optimizer = tf.train.AdagradOptimizer(learning_rate).minimize(loss)\n",
        "\n",
        "\n",
        "global_step = tf.Variable(0, trainable=False)\n",
        "starter_learning_rate = 10e-5\n",
        "learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n",
        "                                           1000, 0.96, staircase=True)\n",
        "# Passing global_step to minimize() will increment it at each step.\n",
        "optimizer = (\n",
        "    tf.train.MomentumOptimizer(learning_rate, momentum=mu).minimize(loss, global_step=global_step)\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFDJy7YUZX8F",
        "colab_type": "code",
        "outputId": "7b2544f8-2daa-4b61-a5b4-44b886e9fff3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "saver = tf.train.Saver()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    init = tf.global_variables_initializer()\n",
        "    sess.run(init)\n",
        "    average_loss = 0\n",
        "    \n",
        "    for step in range(epochs):\n",
        "        epoch_error = 0.0\n",
        "        temp_X , temp_labels = getNextBatchSkipGram(window_size=5, bi_grams_=training_data)\n",
        "        \n",
        "        feed_dict = {train_X : temp_X, train_label : temp_labels}\n",
        "        \n",
        "        op, l = sess.run([optimizer, loss], \n",
        "                                    feed_dict=feed_dict)\n",
        "        \n",
        "        epoch_error += l\n",
        "                \n",
        "        if step % 100 == 0:\n",
        "            print (\"Error at epoch : \", step, \" = \", epoch_error)\n",
        "            \n",
        "    save_path = saver.save(sess, \"./models/model_skipgram_model.ckpt\")\n",
        "    print(\"Model saved in file: %s\" % save_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error at epoch :  0  =  4.074723243713379\n",
            "Error at epoch :  100  =  4.227557182312012\n",
            "Error at epoch :  200  =  3.8662407398223877\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyBXIeUDZX8I",
        "colab_type": "text"
      },
      "source": [
        "##### Embeddings "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0wwUPS_ZX8J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W1_embedding = None\n",
        "W2_embedding = None \n",
        "\n",
        "with tf.Session() as sess:\n",
        "    saver = tf.train.Saver()\n",
        "    # Restore variables from disk.\n",
        "    saver.restore(sess, \"./models/model_skipgram_model.ckpt\")\n",
        "    print(\"Model restored.\")\n",
        "    \n",
        "    # Normalize word2vec \n",
        "    W1_embedding = W1.eval()\n",
        "    \n",
        "    # Normalize word2vec \n",
        "    W2_embedding = W2.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22hOMCZcZX8O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word2vec = np.mean([W1_embedding, W2_embedding], axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2xHBw5LZX8Q",
        "colab_type": "text"
      },
      "source": [
        "##### Projection of embeddings using t-SNE "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksklz3tuZX8R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx2word = {v:k for k, v in word2idx.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5h23tR0DZX8U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.manifold import TSNE\n",
        "model = TSNE()\n",
        "Z = model.fit_transform(word2vec) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rb0gJIsyZX8W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plt.scatter(Z[:,0], Z[:,1])\n",
        "for i in range(len(idx2word)):\n",
        "    try:\n",
        "        plt.annotate(s=idx2word[i].encode(\"utf8\"), xy=(Z[i,0], Z[i,1]))\n",
        "    except:\n",
        "        print (\"bad string:\", idx2word[i])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CksrHxWW8AE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}