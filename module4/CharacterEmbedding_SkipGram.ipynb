{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train character embeddings using word2vec skipgram approach \n",
    "\n",
    "We look at ith character and try to predict (i-1) and (i+1) character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for inline plotting in notebooks\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 611606\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "path = \"./../data/harry_potter_3.txt\"\n",
    "text = open(path).read()\n",
    "\n",
    "corpus_length = len(text)\n",
    "\n",
    "print('corpus length:', corpus_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total no of unique chars: 79\n",
      "\n",
      "Set of characters : \n",
      "['?', \"'\", '\\\\', '-', 'Z', 'w', '!', 'f', 'A', '7', 'M', 'Y', 'x', '\\n', 'H', '5', '6', 'F', 'I', 'K', '3', 'T', 'z', 'y', ',', 'g', '\"', 'B', 'b', 'l', ' ', ':', 'X', 'a', 'R', '&', '*', 't', '(', 'Q', '4', 'h', 's', 'E', 'N', 'j', 'r', '_', 'k', 'u', 'v', 'c', 'W', ')', 'L', '2', 'V', 'i', 'S', 'J', 'p', 'q', '`', 'G', '0', 'n', 'd', '.', 'U', 'e', '9', ';', 'P', 'o', 'C', 'O', '1', 'D', 'm']\n"
     ]
    }
   ],
   "source": [
    "unique_chars = list(set(text))\n",
    "print('total no of unique chars:', len(unique_chars))\n",
    "\n",
    "print (\"\\nSet of characters : \\n\" + str(unique_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classToOneHot(item, classes):\n",
    "\n",
    "\tx = [0. for _ in classes]\n",
    "\t\n",
    "\tx[classes.index(item)] = 1.\n",
    "\n",
    "\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classToOneHot('a', unique_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findClosest(labels, coords, n=3):\n",
    "\tdef dist(p1, p2):\n",
    "\t\treturn np.linalg.norm(np.array(p1)-np.array(p2))\n",
    "\tfor label, pos in zip(labels, coords):\n",
    "\t\tprint(label)\n",
    "\t\tdists = []\n",
    "\t\tfor l2, p2 in zip(labels, coords):\n",
    "\t\t\tif l2==label: continue\n",
    "\t\t\tdists.append((l2, dist(pos, p2)))\n",
    "\t\tdists = sorted(dists, key=lambda x : x[1])\n",
    "\t\tif n == -1:\n",
    "\t\t\tif dists[0][1] >= 0.2:\n",
    "\t\t\t\tprint(\"\\t{}\\t{}\".format(dists[0][0], dists[0][1]))\n",
    "\t\t\telse:\n",
    "\t\t\t\tfor d in dists:\n",
    "\t\t\t\t\tif d[1] <= 0.15:\n",
    "\t\t\t\t\t\tprint(\"\\t{}\\t{}\".format(d[0], d[1]))\n",
    "\t\telse:\t\t\n",
    "\t\t\tfor d in dists[:n]:\n",
    "\t\t\t\tprint(\"\\t{}\\t{}\".format(d[0], d[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare training data X, y\n",
    "# both X,y are are characters \n",
    "\n",
    "skip_window = 1 # how much we see on either side of center word\n",
    "global_index = skip_window # \n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in range(global_index, (corpus_length - skip_window)):\n",
    "\n",
    "    #print i\n",
    "    \n",
    "    X_char = text[i]\n",
    "    y1_char = text[i-1]\n",
    "    y2_char = text[i+1]\n",
    "    \n",
    "    #print X_char\n",
    "    #print y1_char, y2_char\n",
    "    X.append(classToOneHot(X_char, unique_chars))\n",
    "    yp=[classToOneHot(y1_char, unique_chars), classToOneHot(y2_char, unique_chars)] \n",
    "    \n",
    "    y.append(yp)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piyush/Piyush/study/anthill/anthill/lib/python3.5/site-packages/ipykernel_launcher.py:10: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[<tf.Tenso..., inputs=[<tf.Tenso...)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/piyush/Piyush/study/anthill/anthill/lib/python3.5/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[<tf.Tenso..., inputs=[<tf.Tenso...)`\n",
      "  if sys.path[0] == '':\n",
      "/home/piyush/Piyush/study/anthill/anthill/lib/python3.5/site-packages/ipykernel_launcher.py:17: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 1 array(s), but instead got the following list of 611604 arrays: [array([[0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n    ...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-d6eae82f78a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rmsprop'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Piyush/study/anthill/anthill/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    948\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    951\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Piyush/study/anthill/anthill/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Piyush/study/anthill/anthill/lib/python3.5/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0;34m'Expected to see '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' array(s), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;34m'but instead got the following list of '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             raise ValueError(\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 1 array(s), but instead got the following list of 611604 arrays: [array([[0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n    ..."
     ]
    }
   ],
   "source": [
    "nb_cols = len(y[0])\n",
    "y_cols = [np.array([v[i] for v in y], np.float32) for i in range(nb_cols)]\n",
    "\n",
    "input_layer = Input(shape=(len(unique_chars),))\n",
    "encoding = Dense(2, activation='linear')(input_layer)\n",
    "\n",
    "output_1 = Dense(len(unique_chars), activation='softmax')(encoding)\n",
    "output_2 = Dense(len(unique_chars), activation='softmax')(encoding)\n",
    "\n",
    "model = Model(input=[input_layer], output=[output_1, output_2])#, output_3, output_4])\n",
    "\n",
    "encoder = Model(input = [input_layer], output=[encoding])\n",
    "\n",
    "# when using larger windows, remember to add more loss weights\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', loss_weights=[0.5, 0.5])\n",
    "\n",
    "#model.fit(X, y_cols, nb_epoch=15, batch_size=1024, shuffle=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(611604, 79) (2, 611604, 79)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X), np.shape(y_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piyush/Piyush/study/anthill/anthill/lib/python3.5/site-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 1 array(s), but instead got the following list of 611604 arrays: [array([[0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n    ...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-f68c3b1c3cd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Piyush/study/anthill/anthill/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    948\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    951\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Piyush/study/anthill/anthill/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Piyush/study/anthill/anthill/lib/python3.5/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0;34m'Expected to see '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' array(s), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;34m'but instead got the following list of '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             raise ValueError(\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 1 array(s), but instead got the following list of 611604 arrays: [array([[0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n    ..."
     ]
    }
   ],
   "source": [
    "model.fit(X, y_cols, nb_epoch=15, batch_size=1024, shuffle=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?\t-0.09084504842758179\t-0.12432838976383209\n",
      "'\t-0.23532547056674957\t-0.07180963456630707\n",
      "\\\t-0.1999453455209732\t-0.03627222776412964\n",
      "-\t0.1397349238395691\t-0.019741535186767578\n",
      "Z\t-0.1457524448633194\t0.266602098941803\n",
      "w\t-0.15934741497039795\t0.14581629633903503\n",
      "!\t0.1708153486251831\t-0.036524057388305664\n",
      "f\t0.2695719003677368\t0.1507212221622467\n",
      "A\t0.021266639232635498\t-0.02629561722278595\n",
      "7\t0.015011698007583618\t-0.018980056047439575\n",
      "M\t-0.20609042048454285\t0.14379370212554932\n",
      "Y\t-0.2375790774822235\t0.1632525622844696\n",
      "x\t-0.19043685495853424\t0.07522067427635193\n",
      "\n",
      "\t-0.04580160975456238\t-0.07257293164730072\n",
      "H\t0.2172827422618866\t-0.20588108897209167\n",
      "5\t0.15322023630142212\t0.2684010863304138\n",
      "6\t-0.03680652379989624\t0.023195475339889526\n",
      "F\t0.09183758497238159\t0.2500764727592468\n",
      "I\t-0.1524050235748291\t0.26503634452819824\n",
      "K\t-0.015273571014404297\t-0.08274763822555542\n",
      "3\t-0.0817440003156662\t-0.2115616351366043\n",
      "T\t0.03933155536651611\t0.2583785653114319\n",
      "z\t0.25698888301849365\t0.15949445962905884\n",
      "y\t-0.22328343987464905\t0.1450192630290985\n",
      ",\t0.027640193700790405\t-0.06607569754123688\n",
      "g\t0.06918290257453918\t0.1904805302619934\n",
      "\"\t-0.12015964090824127\t-0.19428491592407227\n",
      "B\t0.13468784093856812\t-0.12466549873352051\n",
      "b\t0.049229830503463745\t0.21997714042663574\n",
      "l\t-0.1601075828075409\t-0.2626621127128601\n",
      " \t0.20942696928977966\t0.0031198859214782715\n",
      ":\t-0.014206022024154663\t0.2224503755569458\n",
      "X\t0.11373409628868103\t0.25434648990631104\n",
      "a\t-0.15173453092575073\t-0.10538551211357117\n",
      "R\t-0.017616093158721924\t0.16391250491142273\n",
      "&\t-0.08099886775016785\t-0.17140695452690125\n",
      "*\t-0.046730563044548035\t-0.0975906252861023\n",
      "t\t0.11566781997680664\t-0.20303407311439514\n",
      "(\t0.1400163471698761\t-0.08530966937541962\n",
      "Q\t0.13337138295173645\t-0.03128904104232788\n",
      "4\t0.07711505889892578\t-0.18037913739681244\n",
      "h\t-0.1699356585741043\t0.14398562908172607\n",
      "s\t-0.26261720061302185\t-0.1378486603498459\n",
      "E\t-0.04658728837966919\t-0.07453972101211548\n",
      "N\t0.12474575638771057\t-0.008487462997436523\n",
      "j\t-0.26033899188041687\t-0.045776307582855225\n",
      "r\t-0.267589807510376\t0.05953750014305115\n",
      "_\t0.1319684088230133\t0.2065826654434204\n",
      "k\t0.10602870583534241\t-0.08334636688232422\n",
      "u\t0.15931838750839233\t-0.2358342707157135\n",
      "v\t-0.059796541929244995\t0.08369976282119751\n",
      "c\t-0.0600888729095459\t-0.24244077503681183\n",
      "W\t-0.2230260819196701\t-0.015660971403121948\n",
      ")\t-0.07266131043434143\t-0.15634122490882874\n",
      "L\t0.1961057186126709\t-0.003910958766937256\n",
      "2\t0.03322437405586243\t-0.16781923174858093\n",
      "V\t-0.15806454420089722\t0.02560877799987793\n",
      "i\t-0.24218523502349854\t0.08474504947662354\n",
      "S\t-0.16703581809997559\t0.05419427156448364\n",
      "J\t0.18255311250686646\t-0.09214016795158386\n",
      "p\t0.2462228536605835\t0.14835456013679504\n",
      "q\t0.16471517086029053\t-0.11945883929729462\n",
      "`\t-0.190911203622818\t-0.1717706024646759\n",
      "G\t-0.10161492228507996\t-0.22912035882472992\n",
      "0\t-0.27034345269203186\t-0.1415400207042694\n",
      "n\t-0.14343473315238953\t-0.22739969193935394\n",
      "d\t-0.2560496926307678\t-0.19760817289352417\n",
      ".\t-0.1706644892692566\t0.20841476321220398\n",
      "U\t0.05873003602027893\t-0.007097989320755005\n",
      "e\t-0.0256517231464386\t-0.1550859957933426\n",
      "9\t-0.10389980673789978\t-0.018381446599960327\n",
      ";\t-0.007996439933776855\t0.1113530695438385\n",
      "P\t0.20183536410331726\t0.25809377431869507\n",
      "o\t-0.10761977732181549\t-0.2410832941532135\n",
      "C\t-0.1751018762588501\t-0.22475986182689667\n",
      "O\t0.19823434948921204\t0.2621117830276489\n",
      "1\t0.2017400562763214\t0.15169993042945862\n",
      "D\t0.063662588596344\t0.15933215618133545\n"
     ]
    }
   ],
   "source": [
    "x2 = [classToOneHot(ch, unique_chars) for ch in unique_chars[:-1]]\n",
    "encodings = encoder.predict(np.array(x2))\n",
    "for ch, e in zip(unique_chars[:-1], encodings):\n",
    "    print(\"{}\\t{}\\t{}\".format(ch, e[0], e[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?\n",
      "\t)\t0.036816708743572235\n",
      "\t&\t0.04809717833995819\n",
      "'\n",
      "\tj\t0.0361027754843235\n",
      "\t\\\t0.05014638975262642\n",
      "\\\n",
      "\tW\t0.030944213271141052\n",
      "\t'\t0.05014638975262642\n",
      "-\n",
      "\tQ\t0.013184822164475918\n",
      "\tN\t0.01874377951025963\n",
      "Z\n",
      "\tI\t0.006834353785961866\n",
      "\t.\t0.06329593807458878\n",
      "w\n",
      "\th\t0.010745336301624775\n",
      "\tM\t0.04678674414753914\n",
      "!\n",
      "\t-\t0.035322029143571854\n",
      "\tQ\t0.037808146327733994\n",
      "f\n",
      "\tz\t0.015339557081460953\n",
      "\tp\t0.023468682542443275\n",
      "A\n",
      "\t7\t0.009625057689845562\n",
      "\t,\t0.040287427604198456\n",
      "7\n",
      "\tA\t0.009625057689845562\n",
      "\tU\t0.04530426859855652\n",
      "M\n",
      "\ty\t0.01723664440214634\n",
      "\th\t0.03615526854991913\n",
      "Y\n",
      "\ty\t0.023169342428445816\n",
      "\tM\t0.03701597824692726\n",
      "x\n",
      "\tS\t0.031459785997867584\n",
      "\ti\t0.05261756852269173\n",
      "\n",
      "\n",
      "\tE\t0.0021179120521992445\n",
      "\t*\t0.025034934282302856\n",
      "H\n",
      "\tu\t0.06524614989757538\n",
      "\tq\t0.10115411132574081\n",
      "5\n",
      "\tX\t0.04191284999251366\n",
      "\tO\t0.04545135423541069\n",
      "6\n",
      "\tv\t0.0647248774766922\n",
      "\t7\t0.06681244820356369\n",
      "F\n",
      "\tX\t0.022308971732854843\n",
      "\tb\t0.05216694623231888\n",
      "I\n",
      "\tZ\t0.006834353785961866\n",
      "\t.\t0.05949295312166214\n",
      "K\n",
      "\t\n",
      "\t0.03217896819114685\n",
      "\tE\t0.03237157315015793\n",
      "3\n",
      "\tG\t0.02651720680296421\n",
      "\tc\t0.03771559149026871\n",
      "T\n",
      "\tb\t0.039656590670347214\n",
      "\tF\t0.05315832793712616\n",
      "z\n",
      "\tf\t0.015339557081460953\n",
      "\tp\t0.015492087230086327\n",
      "y\n",
      "\tM\t0.01723664440214634\n",
      "\tY\t0.023169342428445816\n",
      ",\n",
      "\tA\t0.040287427604198456\n",
      "\tK\t0.046038515865802765\n",
      "g\n",
      "\tD\t0.03163376450538635\n",
      "\tb\t0.03561144694685936\n",
      "\"\n",
      "\tG\t0.03946409374475479\n",
      "\tn\t0.04047614708542824\n",
      "B\n",
      "\tq\t0.030475396662950516\n",
      "\t(\t0.039714913815259933\n",
      "b\n",
      "\tg\t0.03561144694685936\n",
      "\tT\t0.039656590670347214\n",
      "l\n",
      "\tn\t0.03900541365146637\n",
      "\tC\t0.04076039046049118\n",
      " \n",
      "\tL\t0.015062818303704262\n",
      "\t!\t0.05533985421061516\n",
      ":\n",
      "\tR\t0.0586371086537838\n",
      "\tb\t0.06348405033349991\n",
      "X\n",
      "\tF\t0.022308971732854843\n",
      "\t5\t0.04191284999251366\n",
      "a\n",
      "\t?\t0.06376802921295166\n",
      "\t`\t0.07708302140235901\n",
      "R\n",
      "\t;\t0.05343249812722206\n",
      "\t:\t0.0586371086537838\n",
      "&\n",
      "\t)\t0.01721891574561596\n",
      "\t3\t0.04016159474849701\n",
      "*\n",
      "\tE\t0.023051351308822632\n",
      "\t\n",
      "\t0.025034934282302856\n",
      "t\n",
      "\t4\t0.04471645504236221\n",
      "\tu\t0.05460059642791748\n",
      "(\n",
      "\tk\t0.034044299274683\n",
      "\tB\t0.039714913815259933\n",
      "Q\n",
      "\t-\t0.013184822164475918\n",
      "\tN\t0.024378543719649315\n",
      "4\n",
      "\tt\t0.04471645504236221\n",
      "\t2\t0.045652419328689575\n",
      "h\n",
      "\tw\t0.010745336301624775\n",
      "\tM\t0.03615526854991913\n",
      "s\n",
      "\t0\t0.008562774397432804\n",
      "\td\t0.06011930853128433\n",
      "E\n",
      "\t\n",
      "\t0.0021179120521992445\n",
      "\t*\t0.023051351308822632\n",
      "N\n",
      "\t-\t0.01874377951025963\n",
      "\tQ\t0.024378543719649315\n",
      "j\n",
      "\t'\t0.0361027754843235\n",
      "\tW\t0.047949835658073425\n",
      "r\n",
      "\ti\t0.03578844293951988\n",
      "\tx\t0.07873080670833588\n",
      "_\n",
      "\tX\t0.05112605169415474\n",
      "\tF\t0.059179339557886124\n",
      "k\n",
      "\t(\t0.034044299274683\n",
      "\tB\t0.050285354256629944\n",
      "u\n",
      "\tt\t0.05460059642791748\n",
      "\tH\t0.06524614989757538\n",
      "v\n",
      "\t;\t0.058719296008348465\n",
      "\t6\t0.0647248774766922\n",
      "c\n",
      "\t3\t0.03771559149026871\n",
      "\tG\t0.043610163033008575\n",
      "W\n",
      "\t\\\t0.030944213271141052\n",
      "\tj\t0.047949835658073425\n",
      ")\n",
      "\t&\t0.01721891574561596\n",
      "\t?\t0.036816708743572235\n",
      "L\n",
      "\t \t0.015062818303704262\n",
      "\t!\t0.041270047426223755\n",
      "2\n",
      "\t4\t0.045652419328689575\n",
      "\te\t0.060237281024456024\n",
      "V\n",
      "\tS\t0.029960209503769875\n",
      "\tx\t0.059239402413368225\n",
      "i\n",
      "\tr\t0.03578844293951988\n",
      "\tx\t0.05261756852269173\n",
      "S\n",
      "\tV\t0.029960209503769875\n",
      "\tx\t0.031459785997867584\n",
      "J\n",
      "\tq\t0.03262670710682869\n",
      "\t(\t0.04308168962597847\n",
      "p\n",
      "\tz\t0.015492087230086327\n",
      "\tf\t0.023468682542443275\n",
      "q\n",
      "\tB\t0.030475396662950516\n",
      "\tJ\t0.03262670710682869\n",
      "`\n",
      "\tC\t0.05529734492301941\n",
      "\td\t0.07007569074630737\n",
      "G\n",
      "\to\t0.013385443948209286\n",
      "\t3\t0.02651720680296421\n",
      "0\n",
      "\ts\t0.008562774397432804\n",
      "\td\t0.05786146596074104\n",
      "n\n",
      "\tC\t0.03177698329091072\n",
      "\to\t0.03833995386958122\n",
      "d\n",
      "\t0\t0.05786146596074104\n",
      "\ts\t0.06011930853128433\n",
      ".\n",
      "\tI\t0.05949295312166214\n",
      "\tZ\t0.06329593807458878\n",
      "U\n",
      "\tA\t0.04209578409790993\n",
      "\t7\t0.04530426859855652\n",
      "e\n",
      "\t)\t0.047026343643665314\n",
      "\t&\t0.05770337954163551\n",
      "9\n",
      "\tV\t0.06977792084217072\n",
      "\t6\t0.0789312943816185\n",
      ";\n",
      "\tR\t0.05343249812722206\n",
      "\tv\t0.058719296008348465\n",
      "P\n",
      "\tO\t0.0053955260664224625\n",
      "\t5\t0.04969578608870506\n",
      "o\n",
      "\tG\t0.013385443948209286\n",
      "\tn\t0.03833995386958122\n",
      "C\n",
      "\tn\t0.03177698329091072\n",
      "\tl\t0.04076039046049118\n",
      "O\n",
      "\tP\t0.0053955260664224625\n",
      "\t5\t0.04545135423541069\n",
      "1\n",
      "\tp\t0.04460841789841652\n",
      "\tz\t0.05579594522714615\n",
      "D\n",
      "\tg\t0.03163376450538635\n",
      "\tb\t0.06233873963356018\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = unique_chars[:-1]\n",
    "xd = [e[0] for e in encodings]\n",
    "yd = [e[1] for e in encodings]\n",
    "fig, ax = plt.subplots()\n",
    "for i, txt in enumerate(labels):\n",
    "    _ = ax.annotate(txt, (xd[i],yd[i]))\n",
    "\n",
    "\n",
    "findClosest(labels, encodings, n=2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
